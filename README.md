# RAG-Pipeline-Chatbot-n8n-

RAG Pipeline & Chatbot using n8n + Google Gemini

This repository contains my implementation of a Retrieval-Augmented Generation (RAG) pipeline and chatbot using n8n
. The project connects Google Drive, Pinecone, and Google Gemini API to build an interactive chatbot that can fetch and answer queries from documents in real-time.

âš¡ What is n8n?

n8n
 is an open-source workflow automation tool that lets you connect apps, APIs, and databases through visual workflows. Itâ€™s highly flexible, developer-friendly, and supports advanced automation without writing complex boilerplate code.

ğŸ“š What is RAG (Retrieval-Augmented Generation)?

RAG is an AI architecture that enhances LLMs by retrieving context from a vector database before generating a response.

Store data as embeddings in a vector database (Pinecone).

Retrieve relevant documents when a user asks a question.

Send both query + retrieved docs to an LLM (Google Gemini) for a contextual, accurate answer.

This ensures:
âœ… Reliable responses
âœ… Fresh knowledge beyond the LLMâ€™s training cutoff
âœ… Domain-specific intelligence

ğŸ› ï¸ Tech Stack

n8n (self-hosted via Docker) â€“ Workflow automation engine

Google Drive API â€“ Document source

Pinecone â€“ Vector database for embeddings

Google Gemini API â€“ Embeddings + Chat model

OpenRouter API â€“ Optional chat model integration

Recursive Character Text Splitter â€“ Splits text into chunks

AI Agent (n8n) â€“ Orchestrates retrieval + response generation

âš™ï¸ Workflow Overview
ğŸ”¹ Document Ingestion Pipeline

Google Drive Trigger â†’ Detect new/updated files.

Download File â†’ Pull document into n8n.

Default Data Loader â†’ Read and process document.

Recursive Text Splitter â†’ Break into smaller chunks.

Embeddings (Google Gemini) â†’ Convert chunks into vectors.

Store in Pinecone â†’ Save embeddings for retrieval.

ğŸ”¹ Chatbot Pipeline

Chat Message Trigger â†’ User asks a question.

Retrieve from Pinecone â†’ Find most relevant chunks.

AI Agent (n8n) â†’ Combines user query + context.

Google Gemini LLM â†’ Generates contextual response.

Return Answer â†’ Sends reply back to chat interface.
